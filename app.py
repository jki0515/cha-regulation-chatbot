"""
CHA University í•™ì¹™/ê·œì • RAG ì±—ë´‡ v2
=====================================
- GPTê°€ ê²€ìƒ‰ ì „ëµì„ íŒë‹¨ (í‚¤ì›Œë“œ ì¶”ì¶œ + ê²€ìƒ‰ ë°©ì‹ ê²°ì •)
- í‚¤ì›Œë“œ ì „ìˆ˜ ê²€ìƒ‰ + ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í•˜ì´ë¸Œë¦¬ë“œ
- OpenAI ì„ë² ë”© + GPT-4o ë‹µë³€ ìƒì„± + ChromaDB ë²¡í„° ì €ì¥ì†Œ
"""

import os
import sys
import json
import re
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI

# ============================================================
# ì„¤ì •
# ============================================================
CHUNKS_PATH = "chunks.json"
CHROMA_DIR = "./chroma_db"
COLLECTION_NAME = "cha_regulations"

def load_env():
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, val = line.split('=', 1)
                    os.environ[key.strip()] = val.strip()

load_env()
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")


# ============================================================
# 1. ì¸ë±ì‹±
# ============================================================
def build_index():
    print("ì¸ë±ì‹± ì‹œì‘...")
    if not OPENAI_API_KEY:
        print("[ì˜¤ë¥˜] OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    with open(CHUNKS_PATH, 'r', encoding='utf-8') as f:
        chunks = json.load(f)
    print(f"  ì²­í¬ ìˆ˜: {len(chunks)}")

    client = chromadb.PersistentClient(path=CHROMA_DIR)
    try:
        client.delete_collection(COLLECTION_NAME)
    except:
        pass

    openai_ef = embedding_functions.OpenAIEmbeddingFunction(
        api_key=OPENAI_API_KEY,
        model_name="text-embedding-3-small"
    )
    collection = client.get_or_create_collection(
        name=COLLECTION_NAME,
        embedding_function=openai_ef,
        metadata={"hnsw:space": "cosine"}
    )

    batch_size = 100
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        collection.add(
            ids=[f"{i+j}" for j, c in enumerate(batch)],
            documents=[c["text"] for c in batch],
            metadatas=[{"document": c["document"]} for c in batch],
        )
        print(f"  [{i+len(batch)}/{len(chunks)}] ì„ë² ë”© ì™„ë£Œ")

    print(f"\nì¸ë±ì‹± ì™„ë£Œ! ì´ {collection.count()}ê°œ ë²¡í„° ì €ì¥ë¨")


# ============================================================
# 2. GPT ê²€ìƒ‰ ì „ëµ íŒë‹¨
# ============================================================
def analyze_query(query):
    """GPTê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì „ëµì„ ê²°ì •"""
    client = OpenAI(api_key=OPENAI_API_KEY)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": """ë‹¹ì‹ ì€ ëŒ€í•™êµ í•™ì¹™/ê·œì • ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì§ˆë¬¸ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ê²€ìƒ‰ ì „ëµì„ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{
  "search_type": "keyword" ë˜ëŠ” "vector" ë˜ëŠ” "both",
  "keywords": ["ê²€ìƒ‰í• ", "í‚¤ì›Œë“œ", "ëª©ë¡"],
  "vector_query": "ë²¡í„° ê²€ìƒ‰ì— ì‚¬ìš©í•  ìì—°ì–´ ì§ˆë¬¸",
  "reason": "íŒë‹¨ ì´ìœ  í•œ ì¤„"
}

íŒë‹¨ ê¸°ì¤€:
- "~ê°€ ë“¤ì–´ê°„/í¬í•¨ëœ/ì–¸ê¸‰ëœ ê·œì • ì°¾ì•„ì¤˜" â†’ keyword (í•´ë‹¹ ë‹¨ì–´ë¥¼ ì •í™•íˆ í¬í•¨í•˜ëŠ” ì¡°í•­ ì „ìˆ˜ ê²€ìƒ‰)
- "~ì— ëŒ€í•œ ê·œì •ì´ ë­ì•¼?", "~í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´?" â†’ vector (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)
- "~ê´€ë ¨ ê·œì • ëª¨ë‘ ì°¾ì•„ì¤˜" â†’ both (í‚¤ì›Œë“œ + ë²¡í„° ë³‘í–‰)

keywordsì—ëŠ” ì‹¤ì œ ê·œì • ë³¸ë¬¸ì—ì„œ ê²€ìƒ‰í•  í•µì‹¬ ë‹¨ì–´ë§Œ ë„£ìœ¼ì„¸ìš”.
"ê·œì •", "ì¡°í•­", "í•™ì¹™" ê°™ì€ ë©”íƒ€ ë‹¨ì–´ëŠ” ì ˆëŒ€ ë„£ì§€ ë§ˆì„¸ìš”.
ì‚¬ìš©ìê°€ ì°¾ê³ ì í•˜ëŠ” ì‹¤ì§ˆì  ë‚´ìš©ì–´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "AIë¼ëŠ” ìš©ì–´ê°€ ë“¤ì–´ê°„ ê·œì • ì°¾ì•„ì¤˜" â†’ keywords: ["AI"]
- "ì¸ê³µì§€ëŠ¥, ë°ì´í„°, ë””ì§€í„¸ ê´€ë ¨ ì¡°í•­ ëª¨ë‘ ì°¾ì•„ì¤˜" â†’ keywords: ["ì¸ê³µì§€ëŠ¥", "ë°ì´í„°", "ë””ì§€í„¸", "AI"]
- "ì¡¸ì—…í•˜ë ¤ë©´ ì–´ë–¤ ìš”ê±´ì„ ì¶©ì¡±í•´ì•¼ í•´?" â†’ search_type: "vector", vector_query: "ì¡¸ì—… ìš”ê±´ í•™ì  ì´ìˆ˜"
- "ì¥í•™ê¸ˆ ê´€ë ¨ ê·œì •ì—ì„œ ì„±ì  ê¸°ì¤€ ì°¾ì•„ì¤˜" â†’ search_type: "both", keywords: ["ì¥í•™ê¸ˆ", "ì„±ì "], vector_query: "ì¥í•™ê¸ˆ ì„±ì  ê¸°ì¤€"
"""},
            {"role": "user", "content": query}
        ],
        max_tokens=300,
        temperature=0,
    )

    try:
        result_text = response.choices[0].message.content.strip()
        # JSON ë¸”ë¡ ì¶”ì¶œ
        if '```' in result_text:
            result_text = result_text.split('```')[1]
            if result_text.startswith('json'):
                result_text = result_text[4:]
        return json.loads(result_text)
    except:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        return {
            "search_type": "vector",
            "keywords": [],
            "vector_query": query,
            "reason": "ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´"
        }


# ============================================================
# 3. ê²€ìƒ‰ ì—”ì§„
# ============================================================
def get_collection():
    client = chromadb.PersistentClient(path=CHROMA_DIR)
    openai_ef = embedding_functions.OpenAIEmbeddingFunction(
        api_key=OPENAI_API_KEY,
        model_name="text-embedding-3-small"
    )
    return client.get_collection(
        name=COLLECTION_NAME,
        embedding_function=openai_ef,
    )


def load_all_chunks():
    with open(CHUNKS_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)


def keyword_search(keywords):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì „ìˆ˜ ê²€ìƒ‰"""
    chunks = load_all_chunks()
    results = []

    for chunk in chunks:
        text = chunk['text']
        text_lower = text.lower()
        matched = []
        for kw in keywords:
            count = text_lower.count(kw.lower())
            if count > 0:
                matched.append((kw, count))

        if matched:
            score = sum(c for _, c in matched)
            results.append({
                'text': text,
                'document': chunk['document'],
                'matched_keywords': [k for k, _ in matched],
                'score': score
            })

    # ì ìˆ˜ìˆœ ì •ë ¬
    results.sort(key=lambda x: -x['score'])
    return results


def vector_search(query, n_results=15):
    """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
    collection = get_collection()
    results = collection.query(
        query_texts=[query],
        n_results=n_results,
    )
    return results


def execute_search(strategy, n_results=15):
    """ê²€ìƒ‰ ì „ëµì— ë”°ë¼ ê²€ìƒ‰ ì‹¤í–‰"""
    search_type = strategy.get('search_type', 'vector')
    keywords = strategy.get('keywords', [])
    vector_query = strategy.get('vector_query', '')

    all_docs = []
    all_metas = []
    search_info = {}

    # í‚¤ì›Œë“œ ê²€ìƒ‰
    if search_type in ('keyword', 'both') and keywords:
        kw_results = keyword_search(keywords)
        search_info['keyword_total'] = len(kw_results)

        # ë¬¸ì„œë³„ ê·¸ë£¹í•‘í•˜ì—¬ í†µê³„
        doc_set = set(r['document'] for r in kw_results)
        search_info['keyword_docs'] = len(doc_set)
        search_info['keywords'] = keywords

        # ìƒìœ„ ê²°ê³¼ ì¶”ê°€ (ì ìˆ˜ìˆœìœ¼ë¡œ ìµœëŒ€ 30ê°œ)
        seen_texts = set()
        for r in kw_results[:30]:
            text_key = r['text'][:100]
            if text_key not in seen_texts:
                seen_texts.add(text_key)
                all_docs.append(r['text'])
                all_metas.append({
                    'document': r['document'],
                    'matched_keywords': r['matched_keywords']
                })

    # ë²¡í„° ê²€ìƒ‰
    if search_type in ('vector', 'both'):
        query = vector_query if vector_query else ' '.join(keywords)
        if query:
            vec_results = vector_search(query, n_results=n_results)
            seen_texts = set(d[:100] for d in all_docs)

            if vec_results['documents'] and vec_results['documents'][0]:
                for doc, meta in zip(vec_results['documents'][0], vec_results['metadatas'][0]):
                    if doc[:100] not in seen_texts:
                        seen_texts.add(doc[:100])
                        all_docs.append(doc)
                        all_metas.append(meta)

    search_info['search_type'] = search_type
    search_info['total_context'] = len(all_docs)

    return {
        'documents': [all_docs],
        'metadatas': [all_metas],
        'search_info': search_info,
    }


# ============================================================
# 4. ë‹µë³€ ìƒì„±
# ============================================================
def generate_answer(query, search_results, strategy):
    """GPT-4oë¡œ ë‹µë³€ ìƒì„±"""
    client = OpenAI(api_key=OPENAI_API_KEY)

    docs = search_results['documents'][0] if search_results['documents'] else []
    metas = search_results['metadatas'][0] if search_results['metadatas'] else []
    search_info = search_results.get('search_info', {})

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìµœëŒ€ 25ê°œ)
    context_parts = []
    for doc_text, meta in zip(docs[:25], metas[:25]):
        doc_name = meta.get('document', 'ì•Œìˆ˜ì—†ìŒ')
        keywords = meta.get('matched_keywords', [])
        kw_info = f" [ë§¤ì¹­: {', '.join(keywords)}]" if keywords else ""
        context_parts.append(f"[ê·œì •: {doc_name}]{kw_info}\n{doc_text}")

    context = "\n\n---\n\n".join(context_parts)

    # ê²€ìƒ‰ í†µê³„
    stats_parts = []
    if 'keywords' in search_info:
        stats_parts.append(f"í‚¤ì›Œë“œ {search_info['keywords']}ë¡œ ê²€ìƒ‰")
    if 'keyword_total' in search_info:
        stats_parts.append(f"{search_info.get('keyword_docs', 0)}ê°œ ê·œì •ì—ì„œ {search_info['keyword_total']}ê°œ ì¡°í•­ ë°œê²¬")
    stats = f"\n[ê²€ìƒ‰ ì •ë³´: {', '.join(stats_parts)}]" if stats_parts else ""

    system_prompt = """ë‹¹ì‹ ì€ ì°¨ì˜ê³¼í•™ëŒ€í•™êµ(CHA University)ì˜ í•™ì¹™ ë° ê·œì • ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì—­í• :
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ê·œì • ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- ë‹µë³€ ì‹œ ë°˜ë“œì‹œ ê·¼ê±°ê°€ ë˜ëŠ” ê·œì •ëª…ê³¼ ì¡°í•­ì„ ëª…ì‹œí•©ë‹ˆë‹¤.
- ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ê·œì •ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤.
- ì—¬ëŸ¬ ê·œì •ì— ê±¸ì³ ê´€ë ¨ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¢…í•©ì ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
- íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¡°í•­ì„ ì°¾ëŠ” ì§ˆë¬¸ì˜ ê²½ìš°, í•´ë‹¹ í‚¤ì›Œë“œê°€ ì‹¤ì œë¡œ ë“±ì¥í•˜ëŠ” ëª¨ë“  ì¡°í•­ì„ ë¹ ì§ì—†ì´ ë‚˜ì—´í•©ë‹ˆë‹¤.

ë‹µë³€ í˜•ì‹:
- í•µì‹¬ ë‹µë³€ì„ ë¨¼ì € ì œì‹œ
- ê·¼ê±° ê·œì • ë° ì¡°í•­ ë²ˆí˜¸ ëª…ì‹œ
- ì „ìˆ˜ ì¡°ì‚¬ì˜ ê²½ìš° ê·œì •ë³„ë¡œ ì •ë¦¬í•˜ì—¬ í‘œì‹œ
- í•„ìš”ì‹œ ê´€ë ¨ ê·œì • ê°„ ì—°ê´€ì„± ì„¤ëª…"""

    user_message = f"""ë‹¤ìŒì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¨ì˜ê³¼í•™ëŒ€í•™êµ ê·œì • ë‚´ìš©ì…ë‹ˆë‹¤:
{stats}

{context}

---

ì§ˆë¬¸: {query}

ìœ„ ê·œì • ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë¹ ì§ì—†ì´ ë‹µë³€í•´ì£¼ì„¸ìš”."""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ],
        max_tokens=4000,
    )

    return response.choices[0].message.content


# ============================================================
# 5. Streamlit UI
# ============================================================
def run_streamlit():
    import streamlit as st

    st.set_page_config(
        page_title="CHA í•™ì¹™/ê·œì • ì±—ë´‡",
        page_icon="ğŸ“",
        layout="wide"
    )

    st.title("CHA University í•™ì¹™/ê·œì • ì±—ë´‡")
    st.caption("ì°¨ì˜ê³¼í•™ëŒ€í•™êµ í•™ì¹™ ë° ê·œì •ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤ (136ê°œ ê·œì •, 2,059ê°œ ì¡°í•­)")

    with st.sidebar:
        st.header("ì„¤ì •")
        n_results = st.slider("ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 5, 30, 15)
        show_sources = st.checkbox("ì°¸ì¡° ê·œì • í‘œì‹œ", value=True)
        show_strategy = st.checkbox("ê²€ìƒ‰ ì „ëµ í‘œì‹œ", value=True)

        st.divider()
        st.header("ê²€ìƒ‰ ë°©ì‹")
        st.caption("""
        **GPTê°€ ìë™ íŒë‹¨:**
        - í‚¤ì›Œë“œ ì „ìˆ˜ ê²€ìƒ‰
        - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰  
        - í•˜ì´ë¸Œë¦¬ë“œ (ë‘˜ ë‹¤)
        """)

        st.divider()
        try:
            collection = get_collection()
            st.metric("ì´ ë²¡í„° ìˆ˜", collection.count())
        except:
            st.warning("ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("í•™ì¹™/ê·œì •ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            with st.spinner("ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ê²€ìƒ‰ ì¤‘..."):
                try:
                    # 1ë‹¨ê³„: GPTê°€ ê²€ìƒ‰ ì „ëµ íŒë‹¨
                    strategy = analyze_query(prompt)

                    if show_strategy:
                        search_type = strategy.get('search_type', 'vector')
                        keywords = strategy.get('keywords', [])
                        reason = strategy.get('reason', '')
                        
                        type_labels = {
                            'keyword': 'ğŸ”¤ í‚¤ì›Œë“œ ì „ìˆ˜ ê²€ìƒ‰',
                            'vector': 'ğŸ§  ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰',
                            'both': 'ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰'
                        }
                        label = type_labels.get(search_type, search_type)
                        
                        info_text = f"{label}"
                        if keywords:
                            info_text += f" | í‚¤ì›Œë“œ: {keywords}"
                        if reason:
                            info_text += f"\n{reason}"
                        st.info(info_text)

                    # 2ë‹¨ê³„: ê²€ìƒ‰ ì‹¤í–‰
                    results = execute_search(strategy, n_results=n_results)
                    search_info = results.get('search_info', {})

                    if search_info.get('keyword_total'):
                        st.caption(f"ğŸ“Š {search_info.get('keyword_docs', 0)}ê°œ ê·œì •ì—ì„œ "
                                   f"{search_info['keyword_total']}ê°œ ì¡°í•­ ë°œê²¬ â†’ "
                                   f"ìƒìœ„ {search_info.get('total_context', 0)}ê°œë¡œ ë‹µë³€ ìƒì„±")

                    # 3ë‹¨ê³„: ë‹µë³€ ìƒì„±
                    answer = generate_answer(prompt, results, strategy)
                    st.markdown(answer)

                    # ì°¸ì¡° ê·œì •
                    if show_sources and results['metadatas'][0]:
                        doc_count = len(results['documents'][0])
                        with st.expander(f"ì°¸ì¡° ê·œì • ë³´ê¸° ({doc_count}ê°œ ì¡°í•­)"):
                            seen_docs = set()
                            for meta, text in zip(results['metadatas'][0], results['documents'][0]):
                                doc_name = meta.get('document', 'ì•Œìˆ˜ì—†ìŒ')
                                if doc_name not in seen_docs:
                                    seen_docs.add(doc_name)
                                    st.markdown(f"**ğŸ“„ {doc_name}**")
                                keywords = meta.get('matched_keywords', [])
                                if keywords:
                                    st.caption(f"ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(keywords)}")
                                display_text = text if isinstance(text, str) else str(text)
                                # í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸
                                if keywords:
                                    highlighted = display_text
                                    for kw in keywords:
                                        highlighted = highlighted.replace(kw, f"**ğŸ”´ {kw}**")
                                    st.markdown(highlighted)
                                else:
                                    st.text(display_text)
                                st.divider()

                    st.session_state.messages.append({"role": "assistant", "content": answer})

                except Exception as e:
                    error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})


# ============================================================
# ë©”ì¸
# ============================================================
if __name__ == "__main__":
    if "--index" in sys.argv:
        build_index()
    else:
        run_streamlit()
